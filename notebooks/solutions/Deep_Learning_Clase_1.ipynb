{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/dl-facilito-g2/blob/main/notebooks/solutions/Deep_Learning_Clase_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6jO_1gISKxk"
      },
      "source": [
        "# Deep Learning 101 - Clase 1  üß†\n",
        "\n",
        "> **Descripci√≥n:** Cuaderno de contenidos (I) sobre introducci√≥n a _deep learning_ para el Bootcamp en DS con C√≥digo Facilito, 2022. <br>\n",
        "> **Autor:** [Rodolfo Ferro](https://github.com/RodolfoFerro) <br>\n",
        "> **Contacto:** [Twitter](https://twitter.com/rodo_ferro) / [Instagram](https://www.instagram.com/rodo_ferro/) \n",
        "\n",
        "\n",
        "## Contenido\n",
        "\n",
        "### Secci√≥n I\n",
        "\n",
        "1. Brief hist√≥rico\n",
        "2. Unidad Umbralizaci√≥n Lineal (TLU)\n",
        "3. Activaci√≥n y bias ‚Äì El perceptr√≥n\n",
        "\n",
        "### Secci√≥n II\n",
        "\n",
        "4. Aprendizaje en neuronas\n",
        "5. Entrenamiento de una neurona\n",
        "6. Predicciones\n",
        "\n",
        "### Secci√≥n III ‚Äì Tarea\n",
        "\n",
        "7. El dataset a utilizar\n",
        "8. Preparaci√≥n de los datos\n",
        "9. Creaci√≥n del modelo\n",
        "10. Entrenamiento del modelo\n",
        "11. Evaluaci√≥n y predicci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVG2PnSEtQN"
      },
      "source": [
        "## **Secci√≥n I**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPk1Rkc4FZ5g"
      },
      "source": [
        "### **Breve historia de las redes neuronales**\n",
        "\n",
        "Podr√≠amos decir que la historia se remonta a dar un inicio con el modelo neuronal de McCulloch y Pitts de 1943, la **Threshold Logic Unit (TLU)**, o **Linear Threshold Unit**,‚Äã que fue el primer modelo neuronal moderno, y ha servido de inspiraci√≥n para el desarrollo de otros modelos neuronales. (Puedes leer m√°s [aqu√≠](https://es.wikipedia.org/wiki/Neurona_de_McCulloch-Pitts).)\n",
        "\n",
        "Posterior a los TLU, se la historia se complementa con el desarrollo de un tipo de neurona artificial con una **funci√≥n de activaci√≥n**, llamada **perceptr√≥n**. √âsta fue desarrollada entre 1950 y 1960 por el cient√≠fico **Frank Rosenblatt**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uehq48zoSocy"
      },
      "source": [
        "### **Entonces, ¬øqu√© es una neurona artificial?**\n",
        "\n",
        "Una neurona artificial es una funci√≥n matem√°tica que concevida como un modelo de neuronas biol√≥gicas. (Puedes leer un poco m√°s [aqu√≠](https://en.wikipedia.org/wiki/Artificial_neuron).)\n",
        "\n",
        "El modelo general de una **neurona artificial** toma varias **entradas** $x_1, x_2,..., x_n $ y produce una **salida**. Se propuso que las entradas tuviesen **pesos** asciados $w_1, w_2, ..., w_n$, siendo √©stos n√∫meros reales que podemos interpretar como una expressi√≥n de la importancia respectiva para cada entrada de informaci√≥n para el c√°lculo del valor de salida de la neurona. La salida de la neurona, $0$ o $1$, est√° determinada con base en que la suma ponderada, \n",
        "\n",
        "$$\\displaystyle\\sum_{j}w_jx_j,$$\n",
        "\n",
        "<!-- $\\textbf{w}_{Layer}\\cdot\\textbf{x} = \n",
        "\\begin{bmatrix}\n",
        "w_{1, 1} & w_{1, 2} & \\cdots & w_{1, n}\\\\\n",
        "w_{2, 1} & w_{2, 2} & \\cdots & w_{2, n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "w_{m, 1} & w_{m, 2} & \\cdots & w_{m, n}\\\\\n",
        "\\end{bmatrix} \\cdot\n",
        "\\begin{bmatrix}\n",
        "x_1\\\\\n",
        "x_2\\\\\n",
        "\\vdots\\\\\n",
        "x_n\n",
        "\\end{bmatrix}$ -->\n",
        "\n",
        "(para $j \\in \\{1, 2, ..., n\\}$ ) sea menor o mayor que un **valor l√≠mite** que por ahora llamaremos **umbral**. (Aqu√≠ comenzamos con la formalizaci√≥n de lo que es un TLU y c√≥mo funciona.)\n",
        "\n",
        "Visto de otro modo, una neurona artificial puede interpretarse como un sistema que toma decisiones con base en la evidencia presentada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q33kCpXyFgJ_"
      },
      "source": [
        "#### **Implementemos una TLU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLBMuek3lBHd"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# Primero creamos nuestra clase TLU\n",
        "class TLU():\n",
        "    def __init__(self, inputs, weights):\n",
        "        \"\"\"Class constructor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of input values.\n",
        "        weights : list\n",
        "            List of weight values.\n",
        "        \"\"\"\n",
        "\n",
        "        self.inputs = np.array(inputs) # TODO: np.array <- inputs\n",
        "        self.weights = np.array(weights) # TODO: np.array <- weights\n",
        "  \n",
        "    def predict(self, threshold):\n",
        "        \"\"\"Function that operates inputs @ weights.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        threshold : int\n",
        "            Threshold value for decision.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Inner product of data\n",
        "        return (self.inputs @ self.weights) >= threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t42O74IdmKIw"
      },
      "source": [
        "# Now, we need to set inputs and weights\n",
        "inputs, weights = [], [1, 1, 1]\n",
        "\n",
        "questions = [\n",
        "    \"¬∑ ¬øCu√°l es la velocidad? \",\n",
        "    \"¬∑ ¬øRitmo cardiaco? \",\n",
        "    \"¬∑ ¬øRespiraci√≥n? \"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    i = int(input(question))\n",
        "    # w = int(input(\"¬∑ Y su peso asociado es... \"))\n",
        "    inputs.append(i)\n",
        "    weights.append(w)\n",
        "    print()\n",
        "\n",
        "threshold = int(input(\"¬∑ Y nuestro umbral/l√≠mite ser√°: \"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHjy-k33oNFm"
      },
      "source": [
        "tlu = TLU() # TODO Instantiate Perceptron\n",
        "tlu.predict(threshold) # TODO Apply decision function with threshold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUCCwUG6DgCX"
      },
      "source": [
        "### **Bias y funciones de activaci√≥n ‚Äì El perceptr√≥n**\n",
        "\n",
        "_Antes de continuar, introduciremos otro conceptos, el **bias** y la **funci√≥n de activaci√≥n**._\n",
        "\n",
        "La operaci√≥n matem√°tica que realiza la neurona para la decisi√≥n de umbralizaci√≥n se puede escribir como:\n",
        "\n",
        "$$ f(\\textbf{x}) = \n",
        "  \\begin{cases}\n",
        "    0 & \\text{si $\\displaystyle\\sum_{j}w_jx_j <$ umbral o treshold} \\\\\n",
        "    1 & \\text{si $\\displaystyle\\sum_{j}w_jx_j \\geq$ umbral o treshold} \\\\\n",
        "  \\end{cases},$$\n",
        "\n",
        "donde $j \\in \\{1, 2, ..., n\\}$, y as√≠, $\\textbf{x} = (x_1, x_2, ..., x_n)$.\n",
        "\n",
        "De lo anterior, podemos despejar el umbral y escribirlo como $b$, obteniendo:\n",
        "\n",
        "$$ f(\\textbf{x}) = \n",
        "  \\begin{cases}\n",
        "    0 & \\text{si $\\displaystyle\\sum_{j}w_jx_j + b < 0$} \\\\\n",
        "    1 & \\text{si $\\displaystyle\\sum_{j}w_jx_j + b > 0$} \\\\\n",
        "  \\end{cases},$$\n",
        "\n",
        "donde $\\textbf{x} = (x_1, x_2, ..., x_n)$ y $j \\in \\{1, 2, ..., n\\}$.\n",
        "\n",
        "Esto que escribimos como $b$, tambi√©n se le conoce como **bias**, y describe *qu√© tan susceptible la red es a __dispararse__*.\n",
        "\n",
        "Curiosamente, esta descripci√≥n matem√°tica encaja con una funci√≥n de salto o de escal√≥n (funci√≥n [_Heaviside_](https://es.wikipedia.org/wiki/Funci%C3%B3n_escal%C3%B3n_de_Heaviside)), que es una **funci√≥n de activaci√≥n**. Esto es, una funci√≥n que permite el paso de informaci√≥n de acuerdo a la entrada y los pesos, permitiendo el disparo del lo procesado hacia la salida. La funci√≥n de salto se ve como sigue:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4a/Funci%C3%B3n_Cu_H.svg\" width=\"40%\" alt=\"Funci√≥n escal√≥n de Heaviside\">\n",
        "</center>\n",
        "\n",
        "Sin embargo, podemos hacer a una neurona a√∫n m√°s susceptible con respecto a los datos de la misma (entradas, pesos, bias) a√±adiendo una funci√≥n [sigmoide](https://es.wikipedia.org/wiki/Funci%C3%B3n_sigmoide). Esta fue una de las agregaciones de Rosenblatt al momento del desarrollo de su propuesta de perceptr√≥n. La funci√≥n sigmoide se ve como a continuaci√≥n: \n",
        "\n",
        "<center>\n",
        "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/6/66/Funci%C3%B3n_sigmoide_01.svg\" width=\"40%\" alt=\"Funci√≥n sigmoide\">\n",
        "</center>\n",
        "\n",
        "Esta funci√≥n es suave, y por lo tanto tiene una diferente \"sensibililad\" a los cambios abruptos de valores. Tambi√©n, sus entradas en lugar de solo ser $1$'s o $0$'s, pueden ser valores en todos los n√∫meros reales. La funci√≥n sigmoide es descrita por la siguiente expresi√≥n matem√°tica:\n",
        "\n",
        "$$f(z) = \\dfrac{1}{1+e^{-z}}$$\n",
        "\n",
        "O escrito en t√©rminos de entradas, pesos y bias:\n",
        "\n",
        "$$f(z) = \\dfrac{1}{1+\\exp{\\left\\{-\\left(\\displaystyle\\sum_{j}w_jx_j +b\\right)\\right\\}}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G1MY4HQFsEd"
      },
      "source": [
        "#### **Volviendo al ejemplo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSn8VaEoDtHo"
      },
      "source": [
        "# Modificamos para a√±adir la funci√≥n de activaci√≥n\n",
        "class Perceptron():\n",
        "    def __init__(self, inputs, weights):\n",
        "        \"\"\"Class constructor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of input values.\n",
        "        weights : list\n",
        "            List of weight values.\n",
        "        \"\"\"\n",
        "\n",
        "        self.inputs = None # TODO: np.array <- inputs\n",
        "        self.weights = None # TODO: np.array <- weights\n",
        "  \n",
        "    def predict(self, bias):\n",
        "        \"\"\"Function that operates inputs @ weights.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        bias : int\n",
        "            The bias value for operation.\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Inner product of data + bias\n",
        "        # TODO: Apply sigmoid function f(z) = 1 / (1 + e^(-z))\n",
        "        z = (self.inputs @ self.weights) >= bias\n",
        "        return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogPy6NpfERfJ"
      },
      "source": [
        "bias = int(input(\"¬∑ El nuevo bias ser√°: \"))\n",
        "perceptron = Perceptron(inputs, weights)\n",
        "perceptron.predict(bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRGlbVZsFxdk"
      },
      "source": [
        "> Esta es la neurona que usaremos para los siguientes t√≥picos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvmIk2G9EgOQ"
      },
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnY-np7LE3lS"
      },
      "source": [
        "## **Secci√≥n II**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aprendizaje de neuronas\n",
        "\n",
        "Veamos c√≥mo se puede entrenar una sola neurona para hacer una predicci√≥n.\n",
        "\n",
        "Para este problema construiremos un perceptr√≥n simple, como el propuesto por McCulloch & Pitts, usando la funci√≥n sigmoide.\n",
        "\n",
        "#### **Planteamiento del problema:**\n",
        "\n",
        "Queremos mostrarle a una neurona simple un conjunto de ejemplos para que pueda aprender c√≥mo se comporta una funci√≥n. El conjunto de ejemplos es el siguiente:\n",
        "\n",
        "- `(1, 0)` deber√≠a devolver `1`.\n",
        "- `(0, 1)` debe devolver `1`.\n",
        "- `(0, 0)` deber√≠a devolver `0`.\n",
        "\n",
        "Entonces, si ingresamos a la neurona el valor de `(1, 1)`, deber√≠a poder predecir el n√∫mero `1`.\n",
        "\n",
        "> ¬øPuedes adivinar la funci√≥n?\n",
        "\n",
        "#### ¬øQue necesitamos hacer?\n",
        "\n",
        "Programar y entrenar una neurona para hacer predicciones.\n",
        "\n",
        "En concreto, vamos a hacer lo siguiente:\n",
        "\n",
        "- Construir la clase y su constructor.\n",
        "- Definir la funci√≥n sigmoide y su derivada\n",
        "- Definir el n√∫mero de √©pocas para el entrenamiento.\n",
        "- Resolver el problema y predecir el valor de la entrada deseada"
      ],
      "metadata": {
        "id": "I7-Ja9DK9cIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class TrainableNeuron():\n",
        "    def __init__(self, n):\n",
        "        \"\"\"Class constructor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        n : int\n",
        "            Input size.\n",
        "        \"\"\"\n",
        "        \n",
        "        np.random.seed(123)\n",
        "        self.synaptic_weights = 2 * np.random.random((n, 1)) - 1 # TODO. Use np.random.random((n, 1)) to gen values in (-1, 1)\n",
        "\n",
        "    def __sigmoid(self, x):\n",
        "        \"\"\"Sigmoid function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to sigmoid function.\n",
        "        \"\"\"\n",
        "        \n",
        "        # TODO: Return result of sigmoid function f(z) = 1 / (1 + e^(-z))\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def __sigmoid_derivative(self, x):\n",
        "        \"\"\"Derivative of the Sigmoid function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        x : float\n",
        "            Input value to evaluated sigmoid function.\"\"\"\n",
        "\n",
        "        # TODO: Return the derivate of sigmoid function x * (1 - x)\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, training_inputs, training_output, epochs):\n",
        "        \"\"\"Training function.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        training_inputs : list\n",
        "            List of features for training.\n",
        "        training_outputs : list\n",
        "            List of labels for training.\n",
        "        epochs : int\n",
        "            Number of iterations for training.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        history : list\n",
        "            A list containing the training history.\n",
        "        \"\"\"\n",
        "\n",
        "        history = []\n",
        "\n",
        "        real_output = training_output.reshape((len(training_inputs), 1))\n",
        "        \n",
        "        for iteration in range(epochs):\n",
        "            predicted_output = self.predict(training_inputs)\n",
        "            #error = real_output - predicted_output\n",
        "            error = - real_output * np.log(predicted_output) \\\n",
        "                    - (1 - real_output) * predicted_output\n",
        "            error /= len(predicted_output)\n",
        "            adjustment = np.dot(training_inputs.T, error *\n",
        "                                self.__sigmoid_derivative(predicted_output))\n",
        "            self.synaptic_weights += adjustment\n",
        "\n",
        "            history.append(np.linalg.norm(error))\n",
        "        \n",
        "        return history\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        \"\"\"Prediction function. Applies input function to inputs tensor.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : list\n",
        "            List of inputs to apply sigmoid function.\n",
        "        \"\"\"\n",
        "        # TODO: Apply self.__sigmoid to np.dot of (inputs, self.synaptic_weights)\n",
        "        return self.__sigmoid(np.dot(inputs, self.synaptic_weights))"
      ],
      "metadata": {
        "id": "2NKx40hxqmo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generando las muestras\n",
        "\n",
        "Ahora podemos generar una lista de ejemplos basados en la descripci√≥n del problema."
      ],
      "metadata": {
        "id": "Ym_oEzbhxYKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training samples:\n",
        "input_values = [(0, 1), (1, 0), (0, 0)]   # TODO. Define the input values as a list of tuples\n",
        "output_values = [1, 1, 0]  # TODO. Define the desired outputs\n",
        "\n",
        "training_inputs = np.array(input_values)\n",
        "training_output = np.array(output_values).T.reshape((3, 1))"
      ],
      "metadata": {
        "id": "BYW9aYSCxc1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenando la neurona\n",
        "\n",
        "Para hacer el entrenamiento, primero definiremos una neurona. De forma predeterminada, contendr√° pesos aleatorios (ya que a√∫n no se ha entrenado):"
      ],
      "metadata": {
        "id": "DJUYV8H-xf7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Sigmoid Neuron:\n",
        "neuron = TrainableNeuron(2)\n",
        "print(\"Initial random weights:\")\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "cThkcQGMxrX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO.\n",
        "# We can modify the number of epochs to see how it performs.\n",
        "epochs = 10000\n",
        "\n",
        "# We train the neuron a number of epochs:\n",
        "history = neuron.train(training_inputs, training_output, epochs)\n",
        "print(\"New synaptic weights after training: \")\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "WnuCP6eHxtQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos evaluar el entrenamiento de la neurona."
      ],
      "metadata": {
        "id": "7KFucScQncbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "eje_x = np.arange(len(history))\n",
        "\n",
        "fig = px.line(\n",
        "    x=eje_x,\n",
        "    y=history,\n",
        "    title='Historia de entrenamiento',\n",
        "    labels=dict(x='√âpocas', y='Error')\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "8vhWL1nLnZ-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Realizando predicciones"
      ],
      "metadata": {
        "id": "7vPb5a65x0bA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We predict to verify the performance:\n",
        "one_one = np.array((1, 1))\n",
        "print(\"Prediction for (1, 1): \")\n",
        "neuron.predict(one_one)"
      ],
      "metadata": {
        "id": "YlhaCvTeyeYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IHtR4uPEaCO"
      },
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NE4e3KuEVst"
      },
      "source": [
        "## **Secci√≥n III ‚Äì Tarea**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z7JrTygMDSx"
      },
      "source": [
        "### El dataset a utilizar: Naranjas vs. Manzanas\n",
        "\n",
        "El dataset ha sido una adaptaci√≥n de datos encontrados en [Kaggle](https://www.kaggle.com/datasets/theblackmamba31/apple-orange). Dicho dataset est√° compuesto por conjuntos de im√°genes de naranjas y manzanas que ser√°n un utilizados para entrenar una neurona artificial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cargar los datos, primero los descargaremos de un repositorio donde previamente los prepar√© para ustedes. \n",
        "\n",
        "Puedes explorar directamente los archivos fuente del [repositorio en GitHub ‚Äì `apple-orange-dataset`](https://github.com/RodolfoFerro/apple-orange-dataset).\n",
        "\n",
        "Puedes tambi√©n explorar el [script](https://github.com/RodolfoFerro/apple-orange-dataset/blob/main/script.py) que he utilizado para la preparaci√≥n de los mismos."
      ],
      "metadata": {
        "id": "UVg0AU2-Fqzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/RodolfoFerro/apple-orange-dataset/main/training_data.csv\n",
        "!wget https://raw.githubusercontent.com/RodolfoFerro/apple-orange-dataset/main/testing_data.csv"
      ],
      "metadata": {
        "id": "1S81FXVEFzQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxfNdPU3NQge"
      },
      "source": [
        "### Preparaci√≥n de los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "training_df = pd.read_csv('training_data.csv')\n",
        "testing_df = pd.read_csv('testing_data.csv')\n",
        "\n",
        "training_df"
      ],
      "metadata": {
        "id": "4fh3DURvLBvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df['class_str'] = training_df['class'].astype('str')\n",
        "training_df['hover'] = [text.split('/')[-1] for text in training_df['filename']]\n",
        "\n",
        "testing_df['class_str'] = testing_df['class'].astype('str')\n",
        "testing_df['hover'] = [text.split('/')[-1] for text in testing_df['filename']]\n",
        "\n",
        "training_df"
      ],
      "metadata": {
        "id": "8IWxRHjQ4GS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploraci√≥n de los datos"
      ],
      "metadata": {
        "id": "h7SGMNlqx8Dx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos verificar si el conjunto de datos est√° balanceado:"
      ],
      "metadata": {
        "id": "wRHZdY0B4NNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.groupby('class').count()"
      ],
      "metadata": {
        "id": "dOvDsf0V3i7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos explorar c√≥mo se ven los datos en un gr√°fico 3D:"
      ],
      "metadata": {
        "id": "5MVOWcHT4Qiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    training_df,\n",
        "    x='r', y='g', z='b',\n",
        "    color='class_str',\n",
        "    symbol='class_str',\n",
        "    color_discrete_sequence=['#be0900', '#ffb447'],\n",
        "    opacity=0.5,\n",
        "    hover_data=['hover']\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "RXINRt1ox_-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes explorar las im√°genes y sus valores de color utilizando el color picker que ofrece Google: https://g.co/kgs/uarXyu\n",
        "\n",
        "> **Pregunta clave:** ¬øLos datos son linealmente separables? Con lo que hemos explorado hasta ahora, ¬øbasta una neurona para resolver el problema planteado?"
      ],
      "metadata": {
        "id": "L8aw6ijc3QZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creaci√≥n de una neurona artificial\n"
      ],
      "metadata": {
        "id": "npjrVs7jUBC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = TrainableNeuron(3) #TODO: Create a neuron instance\n",
        "neuron.synaptic_weights"
      ],
      "metadata": {
        "id": "eHmZ4nnccToB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del modelo\n",
        "\n",
        "Para entrenar el modelo, simplemente utilizamos el m√©todo `.train()` del modelo."
      ],
      "metadata": {
        "id": "B4DmYPVAUJ2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_inputs = training_df[['r', 'g', 'b']].values / 255.\n",
        "training_output = training_df['class'].values\n",
        "\n",
        "training_inputs, training_output"
      ],
      "metadata": {
        "id": "_0o5NZsB7ORw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = neuron.train(training_inputs, training_output, epochs=1000) #TODO: Train a neuron"
      ],
      "metadata": {
        "id": "KX3X_t7B73NV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluaci√≥n y predicci√≥n\n",
        "\n",
        "Podemos evaluar el entrenamiento de la neurona."
      ],
      "metadata": {
        "id": "_2oyTh_jMAIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "eje_x = np.arange(len(history))\n",
        "\n",
        "fig = px.line(\n",
        "    x=eje_x,\n",
        "    y=history,\n",
        "    title='Historia de entrenamiento',\n",
        "    labels=dict(x='√âpocas', y='Error')\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "buRgAf7xLvln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> **Pregunta clave:** ¬øQu√© sucede con la historia de entrenamiento?\n",
        "\n",
        "> **Pro-tip:** Exploremos con una nueva funci√≥n de p√©rdida, qu√© tal la utilizada usualemente en una regresi√≥n log√≠stica: https://developers.google.com/machine-learning/crash-course/logistic-regression/model-training"
      ],
      "metadata": {
        "id": "KMX5Gjzu92e1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para predecir un color de ejemplo:"
      ],
      "metadata": {
        "id": "ZsC5ELq7Ad-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparamos los datos\n",
        "sample_index = 0\n",
        "\n",
        "input_sample = testing_df[['r', 'g', 'b']].iloc[sample_index].values\n",
        "# input_sample = np.array([])\n",
        "print('Color real:', input_sample)\n",
        "\n",
        "input_sample = input_sample / 255.\n",
        "print('Color transformado:', input_sample)\n",
        "\n",
        "real_class = testing_df[['class']].iloc[sample_index].values\n",
        "print('Clase real:', real_class)"
      ],
      "metadata": {
        "id": "kLqvq2cnUfdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuron.predict(input_sample).tolist()"
      ],
      "metadata": {
        "id": "l8mB_4-T6l7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar esta tarea, vamos a utilizar funciones de scikit-learn para la que nos permitir√°n realizar la evaluaci√≥n de resultados en el conjunto de pruebas. (Utilizar [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score))"
      ],
      "metadata": {
        "id": "8ubrtbZdoJ-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    *********\n",
        "</center>"
      ],
      "metadata": {
        "id": "hMCddqlrYosR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    testing_df,\n",
        "    x='r', y='g', z='b',\n",
        "    color='class_str',\n",
        "    symbol='class_str',\n",
        "    color_discrete_sequence=['#be0900', '#ffb447'],\n",
        "    opacity=0.5,\n",
        "    hover_data=['hover']\n",
        ")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "20x0UwqUAtdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(testing_df, threshold=0.5):\n",
        "    testing_inputs = testing_df[['r', 'g', 'b']].values / 255.\n",
        "    testing_output = testing_df['class'].values\n",
        "\n",
        "    predictions = []\n",
        "    for test_input in testing_inputs:\n",
        "        if neuron.predict(test_input)[0] <= threshold:\n",
        "            prediction = 0\n",
        "        else:\n",
        "            prediction = 1\n",
        "        predictions.append(prediction)\n",
        "    predictions = np.array(predictions)\n",
        "\n",
        "    return testing_output, predictions"
      ],
      "metadata": {
        "id": "tccP9w_EBGvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        " \n",
        "\n",
        "testing_output, predictions = get_predictions(testing_df, threshold=0.5)\n",
        "result = accuracy_score(testing_output, predictions)\n",
        "print(f'Accuracy: {result * 100:.6}%')"
      ],
      "metadata": {
        "id": "JZvNFNY4B-Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Pregunta clave:** ¬øQu√© sucede si cambiamos el _threshold_ a 0.7? A veces conviene explorar el valor de umbral que seleccionamos y no siempre dar por hecho que 0.5 va a funcionar todas las veces. <br><br>\n",
        "> Lee m√°s aqu√≠: https://ploomber.io/blog/threshold/"
      ],
      "metadata": {
        "id": "fYFSRK0P_c1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Para resolver la tarea, el reto es:** Mejor accuracy obtenido en la clase.\n",
        "\n",
        "**Puedes explorar:**\n",
        "- Utilizar 1 a 3 variables (de las dadas).\n",
        "- Investigar e implementar una nueva funci[texto del v√≠nculo](https://)√≥n para estimar el error.\n",
        "- Realizar transformaciones en los datos.\n",
        "- Entrenar por m√°s √©pocas.\n",
        "- Mover el umbral para definir la clase.\n",
        "- Explorar otras funciones de activaci√≥n.\n",
        "- Generar tu nuevo dataset de datos a partir de las im√°genes originales."
      ],
      "metadata": {
        "id": "QKp_PZ_NDqbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------\n",
        "\n",
        "> Contenido creado por **Rodolfo Ferro**, 2022. <br>\n",
        "> Puedes contactarme a trav√©s de Insta ([@rodo_ferro](https://www.instagram.com/rodo_ferro/)) o Twitter ([@rodo_ferro](https://twitter.com/rodo_ferro))."
      ],
      "metadata": {
        "id": "hSdbQU3e6-Ky"
      }
    }
  ]
}